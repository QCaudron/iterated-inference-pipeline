\documentclass[a4paper,11pt]{article}

\usepackage[latin1]{inputenc}
 \usepackage[T1]{fontenc}
 \usepackage[normalem]{ulem}
 \usepackage[english]{babel}
 \usepackage{verbatim}
 \usepackage{graphicx}
\usepackage{algorithmic} 
\usepackage{algorithm} 
\usepackage{amsthm, amsmath, amssymb, amsfonts}
\usepackage[modulo,mathlines]{lineno}
\usepackage{array} 
%\bibliographystyle{ieeetr}


\usepackage{chngpage}
\usepackage[round]{natbib}
\usepackage{amssymb,amsmath,amsthm,amscd}
\usepackage{mathrsfs,IEEEtrantools}
\usepackage[left=1.5in, right=1.0in, top=2.0in, bottom=1.0in]{geometry}
% Adjust margins for aesthetics
\addtolength{\voffset}{-0.5in}
\addtolength{\hoffset}{-0.3in}
\addtolength{\textheight}{1cm}


\theoremstyle{plain} % style plain
\newtheorem{theo}{Theorem}
\newtheorem{cor}[theo]{Corollaire}
\newtheorem{prop}[theo]{Proposition}
\newtheorem{lem}[theo]{Lemme}
\newtheorem{conj}[theo]{Conjecture}
\newtheorem*{theoetoile}{Théorème} % théorème non numéroté
\newtheorem*{conjetoile}{Conjecture} % conjecture non numérotée



\newcommand{\argmax}{\operatornamewithlimits{argmax}} 

\begin{document}

\title{Plug-and-play Bayesian inference for compartmental models in PLOM}
\author{Joseph Dureau, S\'ebastien Ballesteros}

\maketitle

\section{Introduction}
\section{Compartmental models}
\subsection{Definition}

Compartmental models are a general framework used to represent the state of a countable population (of humans, animals, molecules, etc) and its evolution. At a given time $t$, the population is described by the number of individuals in each of $n$ possible states: the ensemble of individuals in a same state defines what is termed as a compartment. Each individual belongs to one and only one compartment. Individuals within a same compartment are considered indistinguishable. We will consider in this document that $n$ is known, fixed, and finite. 

Each compartment can correspond to very diverse characterisations, depending on the context. They can be used to track the status of an individual with regards to a given disease in a human or animal population (susceptible or infected, for example), their age or their geographical location. Additionnally, compartments can be used to track the number of specimens of different animal species in an ecosystem, as in the Lotka-Volterra predator-prey model. They can also be used in physics and chemistry to determine molecule types, their electronic charge or radioactive state, for example. Less classical illustrations of the use of compartmental models include tracking the spread of rumors among a population,  or the propagation of economic difficulties among countries following a financial crisis.

We note $z^{(i)}_t$ the size of compartment $i$ ($1\leq i \leq c$) at time $t$, and $z_t=[z_t^{(1)},..,z_t^{(c)}]$. A model is defined by a (finite) number $m$ of transformations of the system called reactions (the ensemble of all indexes is noted $\mathcal{R})$. These reactions correspond to one or several individuals passing from one compartment to another, or arriving or leaving the total population. In any case, each reaction $k$ is characterised by its effect on the structure of the population corresponding to a vector $l^{(k)}\in\mathbb{Z}^c$, and its intensity of occurrence. In the remainder of this document, we will make the classic assumption that the probability of occurrence of each reaction is proportional to the number of individuals in a given compartment. The latter can be specified through a mapping $\chi:\mathcal{R}\rightarrow [1;c]$ such that the transition rate of reaction $k$ can be written $r^{(k)}_t(z_t,\theta) z^{\chi(k)}_t$. This assumption implies the density dependance of transition rates, i.e. the transition rates of the model where the state variable has been normalised ($\dot{z}_t=z_t/N$) can be simply written as $r^{(k)}_t(z_t,\theta) \dot{z}^{\chi(k)}_t$.

We allow for these rates to depend on time, in order to reflect  the influence of potential forcing of external factors on the system, and to depend on a finite set of constant quantities gathered in a parameter vector $\theta$. In the remaining of this document, we will define compartmental models using the following formalism:

\begin{center}
\begin{tabular}{ccc}
%\hline
\textbf{Reaction} & \textbf{Effect}   & \textbf{Rate}   \tabularnewline
\hline
reaction $1$ & $z_t\rightarrow z_t + l^{(1)}$ & $r^{(1)}(z_t,\theta)$  \tabularnewline
... 		& ... & ...  \tabularnewline
reaction $k$  & $z_t\rightarrow z_t + l^{(k)}$ & $r^{(k)}(z_t,\theta)$  \tabularnewline
... 		& ... & ...  \tabularnewline
reaction  $m$ & $z_t\rightarrow z_t + l^{(m)}$ & $r^{(m)}(z_t,\theta)$  \tabularnewline
%\hline
\end{tabular}
%\end{table}
\end{center}


Formally, this framework leads to the definition of a Markovian jump process, which dynamic can be expressed 
in the following way:

\begin{center}
\underline{Markovian jump process compartmental model}
\begin{IEEEeqnarray}{rCl}
\label{eq:ReferenceJump}
P(z_{t+dt}=z_t+l^{(k)}|z_t) &=&r_t^{(k)}(z_t,\theta) z^{\chi(k)}_t dt + o(dt) \;\;\;\;\;\ \text{for any } k\in \mathcal{R}\\
P(z_{t+dt}=z_t|z_t) &=& \big(1-\sum_{ k\in \mathcal{R}} r_t^{(k)}(z_t,\theta) z^{\chi(k)}_tdt\big) + o(dt)\nonumber
\end{IEEEeqnarray}
\end{center}


Under some regularity conditions detailed in \cite{Ethier1986}, \cite{Fuchs2013} or \cite{Guy2013}, and due to the density-dependance of transition rates, the dynamic of the system converges to a deterministic behaviour as the population size tends to infinity. For finite populations, the additional stochastic behaviour is termed \emph{demographic} stochasticity. 



\subsection{Environmental stochasticity}

Extensions of the compartmental modeling framework introduced in the previous section have been proposed by the authors of \cite{Breto2009}, to account for additional sources of uncertainty related to fluctuations in extrinsic determinants of the epidemic. This uncertainty is reflected through additional sources of stochasticity, termed \emph{environmental} stochasticity. The approach suggested in \cite{Breto2009} is to consider stochastic transition rates $\tilde{r}^{(k)}_t$ for a subset $\mathcal{R}^e$, under the following constraints for all $t$:


\begin{center}
\begin{IEEEeqnarray}{rCl}
\mathbb{E}\big(\tilde{r}^{(k)}_t\big) &\sim& r^{(k)}_t\nonumber\\
\tilde{r}^{(k)}_t &\geq& 0\nonumber
\end{IEEEeqnarray}
\end{center}

However, uncertain variations of extrinsic factors cannot always be modeled through high-frequency independent fluctuations. The evolution of climate, for example, has been shown to exhibit complex seasonal and inter-annual variations that influence epidemic dynamics \cite{Viboud2004}. Following the work of \cite{Cazelles1997} and \cite{Cori2009}, the authors of \cite{Dureau2013a} have proposed a general inferential framework for time-varying parameters, that is extended in the present document. Under this approach, parameters are modeled through stochastic differential equations or extensions thereof. The state vector is extended with additional components $x^{\theta_t}_t$ which dynamic is determined by the following equation: 
 
\begin{IEEEeqnarray}{rCl}
dx^{\theta_t}_t = \mu^{\theta_t}(x^{\theta_t}_t,\theta)dt + L^{\theta_t}dB_t^{Q^{\theta_t}}
\end{IEEEeqnarray}


Note that some constraints as positivity or boundedness generally need to be preserved when allowing parameters to vary over time, which is achieved by defining $x^{\theta_t}$ as the respectively the log or logit transformation of the quantity of interest. 


\subsection{Examples}
\subsection{Tractable approximations of compartmental models}
\subsubsection{Ordinary differential equations}

The simplest and most stringent approximation of compartmental models are ordinary differential equations (ode's):

\begin{align}
	\frac{dz_t}{dt}&=  \sum_{k \in \mathcal{R}} l^{(k)}  r^{(k)} (z_t,\theta) z^{\chi(k)}_t
\end{align}


Under this formalism, the number of individuals in each compartment takes continues values, and varies continuously (and in a differentiable manner) over time. More specifically, all kind of demographic or environmental stochasticity are neglected, leading  the state of the system to evolve deterministically. From a practical perspective, the use of ordinary differential equations drastically simplifies the process of Bayesian inference, mainly due to the deterministic one-to-one mapping between trajectories $z_{0:T}$ and parameters $\theta$.

This formalism can be legitimately used for large populations and when all significant environmental factors have been explicitly incorporated in the deterministic skeleton of the model. However, in alternative cases results should be treated with caution, and the use of alternative formalisms accounting for  demographic or environmental stochasticity may be required.



\subsubsection{Stochastic differential equations}

Stochastic differential equations (sde's) are a natural extension of ode's, wherein state variables still take continuous values over time, and evolve continuously over time, but trajectories of the system are no longer deterministic and differentiable due to the introduction of a driving Brownian motion reflecting the stochasticity of the system. To introduce this formalism, we rely on the notations used by the author of \cite{Sarkka2006} that will be helpfull to handle and represent different and independent sources of stochasticity:


\begin{IEEEeqnarray}{rCl}
\label{eq:sde}
dx_t = \mu_t(x_t,\theta)dt + LdB_t^{Q_t}
\end{IEEEeqnarray}


In this equation, $\mu_t$ is referred to as the drift, $L$ as the dispersion matrix, and $Q_t$ as the diffusion matrix of the driving Browian motion. In particular, in our models the state variable $x_t$ is built from the concatenation of $z_t$ and $x^{\theta_t}_t$ respectively corresponding to the variables describing the structure of the population and to the variables monitoring the evolution of diffusing parameters over time. We can reformulate \ref{eq:sde}, utilising the notations that have been introduced earlier in this document:

\begin{IEEEeqnarray}{rCl}
dz_t &=& \sum_{k \in \mathcal{R}} l^{(k)}  r^{(k)} (z_t,\theta) z^{\chi(k)}_t dt + LdB_t^{Q_t}\nonumber\\
dx^{\theta_t}_t &=& \mu^{\theta_t}(x^{\theta_t}_t,\theta)dt + L^{\theta_t}dB_t^{Q^{\theta_t}}\nonumber
\end{IEEEeqnarray}


Note that the deterministic skeleton of the population variables' dynamic correspond to the ode model introduced in the previous section. The dispersion matrix $Q_t$ is a square matrix of size $n_{Q_t}\times n_{Q_t}$, and $L$ is a rectangular matrix of size $c\times n_{Q_t}$. Let us illustrate the use of these objects by introducing how demographic stochasticity can be incorporated in the model, based on the diffusion approximation, and further how the white noise environmental stochasticity  can be incorporated.


\paragraph{Diffusion approximation of the demographic stochasticity}\mbox{}\\

In order to provide an SDE approximation of the demographic stochasticity, we rely on theoretical results on state-dependent Markov jump processes  presented in \cite{Ethier1986}. The adaptation of these results on compartmental epidemic models models has been illustrated in \cite{Fuchs2013}. Extensions of these results in non-homogeneous settings are provided in \cite{Guy2013}. 


The diffusion approximation builds up on the definition of jump process models through their master equation:
\begin{IEEEeqnarray}{rCl}
\frac{\partial}{\partial t}P(z_t)=\sum_{k\in\mathcal{R}} r^{(k)} \tilde{z}_{k,t}^{\chi(k)}P(z_t-l^{(k)}) - \sum_{k \in\mathcal{R}} r^{(k)}(z_t,\theta) z^{\chi(k)}_t P(z_t) 
\end{IEEEeqnarray}


Where $\tilde{z}_{k,t}=z_t-l^{(k)}$.
The first term corresponds to the probability for the state vector of evolving into $z_t$, and the second corresponds to the probability of leaving the state $z_t$. In a SIR model setting, the master equation becomes:
\begin{IEEEeqnarray}{rCl}
\frac{\partial}{\partial t}P(S_t,I_t,R_t)&=& \beta \frac{(S_t+1)}{N}(I_t-1)P(S_t+1,I_t-1,R_t)  \nonumber \\
 & &  +\; \gamma (I_t+1)P(S_t,I_t+1,R_t-1)\\
 & &  - \; \beta \frac{S_t}{N}I_tP(S_t,I_t,R_t) \nonumber \\
 & &  - \; \gamma I_tP(S_t,I_t,R_t)\nonumber
\end{IEEEeqnarray}

This equation can be written in terms of normalised quantities, with $\varepsilon=1/N$:
\begin{IEEEeqnarray}{rCl}
\frac{\partial}{\partial t}P(s_t,i_t,r_t)&=& \frac{1}{\varepsilon} \beta (s_t+\varepsilon)(i_t-\varepsilon)P(s_t+\varepsilon,i_t-\varepsilon,,r_t)  \nonumber \\
 & &  +\;   \frac{1}{\varepsilon} \gamma (i_t+\varepsilon)P(s_t,i_t+\varepsilon,r_t-\varepsilon)\\
 & &  -\;   \frac{1}{\varepsilon} \beta s_t i_tP(s_t,i_t,r_t)  \nonumber\\
 & &  -\;   \frac{1}{\varepsilon} \gamma i_tP(s_t,i_t,r_t) \nonumber
\end{IEEEeqnarray}

The diffusion approximation relies on the limit of this expression when $\varepsilon \rightarrow 0$ while $N$ is kept constant. The author of \cite{Fuchs2013} shows that in this case, the former master equation converges to the following partial differential equation:
\begin{IEEEeqnarray}{rCl}
\frac{\partial}{\partial t}P(s_t,i_t,r_t)&=& \frac{\partial}{\partial s} \beta s_t i_t P(s_t,i_t,r_t)  -  \frac{\partial}{\partial i} (\beta s_t i_t -\gamma i_t)P(s_t,i_t,r_t)  \nonumber \\
 & &  +\;  \frac{1}{2} \frac{\partial^2}{\partial s^2} \frac{1}{N} \beta s_t i_t P(s_t,i_t,r_t)  \\
 & &  -\;  \frac{1}{2} \frac{\partial^2}{\partial i^2} \frac{1}{N} (\beta s_t i_t -\gamma i_t) P(s_t,i_t,r_t)   \nonumber\\
 & &  -\;   \frac{\partial^2}{\partial s \partial i} \frac{1}{N} \beta s_t i_t P(s_t,i_t,r_t)\nonumber,\label{eq:Ch2_pde}
\end{IEEEeqnarray}

which is equivalent to
\begin{IEEEeqnarray}{rCl}
\frac{\partial}{\partial t}P(s_t,i_t,r_t)&=& -\frac{\partial}{\partial x}[\dot{A}(s_t,i_t,r_t)P(s_t,i_t,r_t)] +  \frac{1}{2} \frac{\partial}{\partial x} \frac{\partial}{\partial x} [\dot{\Sigma}(s_t,i_t,r_t)P(s_t,i_t,r_t)]\label{eq:Ch2_pdegen}
\end{IEEEeqnarray}

\vskip0.5cm

Where
\begin{IEEEeqnarray}{rCl}
\;\;\dot{A}(s_t,i_t,r_t) = \left(\begin{array}{c} -\beta s_t i_t \\ \beta s_t i_t - \gamma i_t \\   \gamma i_t \end{array}\right)\end{IEEEeqnarray}

and

\begin{IEEEeqnarray}{rCl}
\dot{\Sigma}(s_t,i_t,r_t) = \frac{1}{N} \left(\begin{array}{ccc} \beta s_t i_t & -\beta s_t i_t & 0 \\ - \beta s_t i_t& \beta s_t i_t + \gamma i_t & - \gamma i_t   \\ 0 &  - \gamma i_t &  \gamma i_t  \end{array}\right)
\end{IEEEeqnarray}


\vskip0.5cm
Following  \cite{Kloeden1999},  \ref{eq:Ch2_pdegen}  is a Fokker-Planck equation corresponding to a diffusion process that is a solution of
\begin{IEEEeqnarray}{rCl}
d\dot{z}_t = \dot{A}(\dot{z}_t)dt + LdB_t^{\dot{Q}_t^{d}} \label{eq:Ch2_sdenorm} 
\end{IEEEeqnarray}

Here, we follow the formalism of \cite{Sarkka2006}  where   $dB_t^{\dot{Q}_t^{d}}$ is a Brownian motion   with  diffusion matrix $\dot{Q}_t^{d}$ and $L$ is a stoichiometric dispersion matrix such that $L\dot{Q}_t^{d} L=\dot{\Sigma}$:  
\begin{IEEEeqnarray}{rCl}
\dot{Q}^d(s_t,i_t) = \frac{1}{N} \left(\begin{array}{cc} \beta s_t i_t & 0\\  0 & \gamma i_t  \end{array}\right)\;\;\;\; and \;\;\;\; L =  \left(\begin{array}{cc} -1  & \;\;\;0\\  \;\;\;1 & - 1 \\ \;\;\;0 & \;\;\;1 \end{array}\right)
\end{IEEEeqnarray}


Equation  \ref{eq:Ch2_sdenorm}  can be transposed in the natural scale of $z_t=[S_t,I_t,R_t]^T$, with $A=N\dot{A}$ and $Q^d = N^2\dot{Q^d} $:
\begin{IEEEeqnarray}{rCl}
dz_t = A(z_t)dt + LdB_t^{Q^d}
\label{eq:Ch2_SDE}
\end{IEEEeqnarray}


This result can be generalised based on the density-dependance property of rates $(r^{(k)}z_t^{\chi(k)})_{1\leq k \leq n}$. Formal proofs for  the general case of density-dependent jump processes can be found in \cite{Ethier1986}. The authors demonstrate that the dynamic of a density-dependent Markov jump process can be approximated with equation  \ref{eq:Ch2_SDE} with $dB$t being a multivariate Brownian motion with diffusion matrix $Q^d = diag\{ r^{(k)}z_t^{\chi(k)},$ $k\in \mathcal{R}\}$, and L being the rectangular stoichiometric matrix which columns are the stoichiometric vectors $l^{(k)}$ with $k\in \mathcal{R}$.  Additionally, the drift component $A(t)$ is determined by:
\begin{IEEEeqnarray}{rCl}
A(z_t) = \sum_{k\in \mathcal{R}} l^{(k)}  r^{(k)}(z_t,\theta)z_t^{\chi(k)}
\end{IEEEeqnarray}

Lastly, the resulting  expression for $\Sigma$ is the following:
\begin{IEEEeqnarray}{rCl}
\Sigma(z_t) = LQ^d L'=\sum_{k\in \mathcal{R}} l^{(k)}  r^{(k)}(z_t,\theta)z_t^{\chi(k)} l^{(k)\prime}
\end{IEEEeqnarray}



\paragraph{Diffusion approximation of the environmental stochasticty}\mbox{}\\


This section focuses on environmental stochasticity. In this perspective, we consider an infinite population leading to a deterministic behaviour in the absence of environmental stochasticity or time-varying parameters following a diffusion:
\begin{IEEEeqnarray}{rCl}
d z_t =   \sum_{k \in \mathcal{R}} l^{(k)}  r^{(k)} (z_t,\theta)z_t^{\chi(k)}dt
\end{IEEEeqnarray}

In the case of the SIR model:
\begin{equation}
\left\{
\begin{IEEEeqnarraybox}[
\IEEEeqnarraystrutmode
\IEEEeqnarraystrutsizeadd{6pt}
{2pt}
][c]{rCl}
dS_t &= &-\beta S_t \frac{I_t}{N} dt \\
dI_t &=& (\beta S_t \frac{I_t}{N}-\gamma I_t) dt\\
dR_t &=& \gamma I_t dt
\end{IEEEeqnarraybox}
\right.
\end{equation}
%\vskip0.5cm

The framework proposed in \cite{Breto2009} introduces environmental stochasticity by replacing deterministic time increments $dt$ by stationnary and nonnegative increments $d\Gamma_t$ with mean $dt$ and variance $\sigma^2 dt$. Here, if environmental noise is put over the infection reaction:
\begin{equation}
\left\{
\begin{IEEEeqnarraybox}[
\IEEEeqnarraystrutmode
\IEEEeqnarraystrutsizeadd{6pt}
{2pt}
][c]{rCl}
dS_t &= &-\beta S_t  \frac{I_t}{N} d\Gamma_t \\
dI_t &=& \beta S_t \frac{I_t}{N} d\Gamma_t -\gamma I_t dt \\
dR_t &=& \gamma I_t dt 
\end{IEEEeqnarraybox}
\right.
\end{equation}
%\vskip0.5cm

We propose to derive a Gaussian formulation of epidemic models with environmental stochasticity by approximating $d\Gamma_t$ as $dt + \sigma dB_t$, i.e. the Gamma-distributed increments are replaced with a deterministic drift and a Brownian motion term with corresponding mean and variance. Thus, the model can be written as a stochastic differential equation:
\begin{equation}
\left\{
\begin{IEEEeqnarraybox}[
\IEEEeqnarraystrutmode
\IEEEeqnarraystrutsizeadd{6pt}
{2pt}
][c]{rCl}
dS_t &= &-\beta S_t \frac{I_t}{N} dt  - \sigma \beta S_t \frac{I_t}{N} dB^{(1)}_t \\
dI_t &=& (\beta S_t \frac{I_t}{N} d\Gamma_t -\gamma I_t)dt  + \sigma \beta S_t \frac{I_t}{N} dB^{(1)}_t\\
dR_t &=& \gamma I_t dt 
\end{IEEEeqnarraybox}
\right.
\end{equation}
\vskip0.5cm


In the general case, independent environmental noise can be enforced upon any subset $\mathcal{R}^e\in \mathcal{R}$ of all reactions:
\begin{IEEEeqnarray}{rCl}
dz_t =   \sum_{k \in \mathcal{R}} l^{(k)}  r^{(k)} (z_t,\theta)z_t^{\chi(k)}dt + L^edB_t^{Q^e}
\end{IEEEeqnarray}

$L^e$ is the $c\times Card(\mathcal{R}^e)$ stoichiometric matrix which columns are the stoichiometric vectors $l^{(k)}$ with $k\in \mathcal{R}^e$. In addition,  if all white noises are independent $dB_t^{Q^e}$ is a Brownian motion with diffusion matrix $Q^e= diag\big\{ \big(\sigma^{(k)}r^{(k)}(z_t,\theta)z_t^{\chi(k)}\big)^2,k\in \mathcal{R}^e\big\}$   containing the variance of the different environmental noises imposed upon the system. 


In addition, it may be useful to enforce correlation between white noises affecting different reactions. In a multi-strain epidemic model, for example, if white noise is meant to capture climatic variability its impact may be the same on all transmission reactions. The latter can be achieved by the introduction of a second level of hierarchy accounting for grouping among noisy reactions. The latter can be determined through a mapping function $\varphi:\mathcal{R}^e\rightarrow[1:n_g]$  so that $\varphi^{-1}(p)$ corresponds to the indexes of  a group of correlated reactions for each $p\in [1:n_g]$. More details can be found in the following paragraph.


\paragraph{Diffusion approximation of compartmental models in the general case}\mbox{}\\



From the previous results, a diffusion approximation of compartmental models in the general case is provided by the following SDE:
\begin{equation}
\left\{
\begin{IEEEeqnarraybox}[
\IEEEeqnarraystrutmode
\IEEEeqnarraystrutsizeadd{6pt}
{2pt}
][c]{rCl}
dz_t &=&  \sum_{k \in \mathcal{R}} l^{(k)}  r^{(k)}(z_t,\theta)z_t^{\chi(k)}dt + LdB^{Q}_t\\
dx^{\theta_t}_t &=& \mu^{\theta_t}(x^{\theta_t}_t,\theta)dt + L^{\theta_t} dB^{Q^{\theta_t}}_t
\end{IEEEeqnarraybox}
\right.
\end{equation}
%\vskip0.5cm

The matrices $L$ and $Q$ are constructed by concatenating the dispersion and diffusion matrices of the different sources of independent noises:
\begin{IEEEeqnarray}{rCl}
L = \left(\begin{array}{ccc}  L^d & L^e \end{array}\right) \;\;\;\; and \;\;\;\;  Q = \left(\begin{array}{ccc}  Q^d & 0 \\ 0 & Q^e \end{array}\right)
\end{IEEEeqnarray}

With $Q^d = diag\{ r^{(k)}(z_t,\theta)z_t^{\chi(k)},$ $k\in \mathcal{R}\}$ and $L^d = [l^{(1)},..,l^{(c)}]$ accounting for the demographic stochasticity on one hand. White noise environmental counterparts are defined in the following way $L^e=[l^{(k)}]_{k\in\mathcal{R}^e}$ is the concatenation of the stoichiometic vectors for noisy reactions. $\varphi$ is the mapping function defined over $\mathcal{R}^e$ that attributes an equal index in $[1;n_g]$ to reactions upon which correlated environmental noise is enforced. From this function, a rectangular $card(\mathcal{R}^e)\times n_g$ dispersion matrix $L^g$ can be constructed in which the column of group $p$ is filled with $r(z_t,\theta)z_t^{\chi(k)}$ on rows corresponding to reactions such that $\varphi(k)=p$, and zero's everywhere else. With $Q^g=diag\big\{ \big(\sigma^{(p)})^2,p\in [1:n_g]\big\}$, $Q^e$ can be computed as $Q^e=L^g Q^g L^{g\prime}$. Naturally, this method for constructing correlated noise terms hold for uncorrelated noises.



\subsubsection{Poisson process with stochastic rates}


The continuous approximation of the number of individuals contained in each compartment, and its evolution, may be questionable when populations as stake are not large enough and more specifically when the size of at least one compartment becomes small. Such situations typically correspond to the extinction of diseases or species in epidemic or ecological models. The Markovian jump process introduced earlier accounts for the discrete nature of the size of each compartment, and the discontinuities induced by the occurrence of each reaction. Nevertheless, due to the density-dependence of transformation rates the frequency of reactions increases infinitely as $N\rightarrow\infty$. Hence, the reference Markov jump process formalism quickly becomes intractable for other than small populations. The authors of \cite{Breto2009} have proposed an approximation of the Markov jump process based on a multinomial approximation of the number of reactions occurring over a short period of time $dt$. Here, we reformulate the solution proposed in \cite{Breto2009} and extend it to the general framework for compartmental models proposed in PLOM. 


The Poisson process model determines the probability that each reaction $k$ ($k\in\mathcal{R}$) respectively occurred $n_k$ times over a given period $dt$. If all sources of environmental stochasticity are neglected:

\begin{IEEEeqnarray}{rCl}
p(n_1,\dots,n_m|z_t,\theta) = \prod_{i=1}^c\left\{  M_{i}  \left( 1-\sum_{\chi(k)=i} p_{k} \right) ^{\overline{n}_{i}}  \prod_{\chi(k)=i} \left(  p_{k} \right)^{n_{k}}   \right\} + o(dt)\nonumber
\end{IEEEeqnarray}

Using the following notations: 
\begin{IEEEeqnarray}{rCl}
&&p_{k}=p_{k}  \left(  r^{(k)}(z_t,\theta)z^{\chi(k)}_t dt\right) = \left( 1-\exp \left\{-\sum_{\chi(k')=i}r^{(k')}(z_t,\theta)z^{\chi(k')}_t dt \right\} \right)\frac{r^{(k)}(z_t,\theta)}{\sum_{\chi(k')=i} r^{(k')}(z_t,\theta)}\nonumber\\
&&\overline{n}_{i}=z_t^{(i)} - \sum_{\chi(k)=i} n_{k}\nonumber\\
&&M_{i} = \left( \begin{array}{c} z_t^{(i)} \\ \{n_{k}\}_{\chi(k)=i} \; \overline{n}_i  \end{array}  \right) \;\;\;\;\;\text{
(multinomial coefficient)}\nonumber
\end{IEEEeqnarray} 


In addition, white noise can be introduced on reaction $k$ ($k\in\mathcal{R}^e$) by replacing time increments $dt$ by random increments $d\Gamma_k$ with Gamma distribution, mean $dt$ and standard deviation $\sigma^{(k)}\sqrt{dt}$:

\begin{IEEEeqnarray}{rCl}
&&p_{k}=p_{k}  \left(  r^{(k)}z^{\chi(k)}_t d\Gamma_k \right) = \left( 1-\exp \left\{-\sum_{\chi(k')=i}r^{(k')}(z_t,\theta)z^{\chi(k')}_t d\Gamma_{k'} \right\} \right)\frac{r^{(k)}d\Gamma_k}{\sum_{\chi(k')=i} r^{(k')}d\Gamma_{k'}}\nonumber
\end{IEEEeqnarray} 

Lastly, time-varying parameters can be introduced in a similar manner as under previous formalisms:


\begin{IEEEeqnarray}{rCl}
dx^{\theta_t}_t = \mu^{\theta_t}(x^{\theta_t}_t,\theta)dt + L^{\theta_t}dB_t^{Q^{\theta_t}}\nonumber
\end{IEEEeqnarray}



\section{Library of inference methods}

In this section we will consider the slightly more general class of state space models evolving in continuous time, with discrete observations. The state of the system at time $t$ is note $x_t$. We will abusively note $x_i$ the value of $x_t$ at time $t_i$, hence $x_{0:n}$ denotes a trajectory of the system between $t_0$ and $t_n$. The prediction density $p(x_{i+1}|x_i,\theta)$ is generally untractable, which means that the probability of a path cannot be computed. However, we consider that it is possible to simulate trajectories from this prediction density.
In addition, an observation model $p(y_i|x_i,\theta)=f(h(x_i);y_{i},\theta)$ needs to be defined, to determine what is the probability of observing $y_i$ conditionnally on the set of parameters $\theta$ and its proxy $h(x_i)$ built from the state of the system $x_i$.

\subsection{Inference for state space models}

State space models can be seen as a hypothesised probabilistic relation between the trajectories $x_{0:n}$ of a system and constant related  quantities grouped in a parameter vector $\theta$. This relation determines a joint probability density $p(x_{0:n},\theta)$. From a Bayesian perspective, the knowledge or the uncertainty over the components of $\theta$ are enforced through the \emph{a priori} density $p(\theta)$. For a given parameter vector $\theta$, the likely trajectories of the system are reflected by the density $p(x_{0:n}|\theta)$. The primary objective of inference with state space models is the estimation of the posterior density $p(\theta|y_{1:n})$, and of the marginal density $p(x_{0:n}|y_{1:n})$. Additionally, model choice indicators can play a key role in disentangling between different hypothesised state space models \citep{Spiegelhalter2002}.

As suggested by the now classic motto "all models are wrong, but some are useful" \citep{Box1987}, models will only ever be a rough approximation of a complex reality. Yet, the latter does not prevent from following a scientific inductive approach to derive conclusions from the confrontations of models to data. By reconstructing the trajectory $x_{0:n}$ of the partially observed system or learning about uncertain components of $\theta$, experience suggests that this process is likely to revise our understanding of infectious diseases \citep{King2008}.  As in any other context, the validity of inference results shall be critically examined at least from a three-fold perspective. First, the uncertainties associated with the data collection should be reflected in the observation model. Then, the limitations of the model itself should be acknowledged and questioned, while considering the practical feasibility of  proposing extensions to palliate the imperfections of the model. A minimal condition requires the output of the model to be able to fit the available observations of mechanisms they are meant to reproduce \citep{Gelman2012}. At last, the information derived regarding $x_{0:n}$  and  $\theta$, reflected by the discrepancies between their marginal prior and posterior densities, should not be considered as hard truth but rather as plausible and testable hypothesis  \citep{Popper2002}. 


An additional dimension arises when working with state space models, that requires specific attention. Although the joint posterior density $p(x_{0:n},\theta|y_{1:n})$ can  be computed pointwise  up to a multiplicative constant hrough the Bayes rule (for a given trajectory $x_{0:n}$ and parameter $\theta$), there is generally no direct way of deriving tractable formulas for the quantities of interest, i.e. $p(\theta|y_{1:n})$ and $p(x_{0:n}|y_{1:n})$. For sufficiently small-dimensional problems, efficient solutions for routine inference are offered by Gibbs MCMC samplers as the ones implemented in the Bugs library \citep{Lunn2000}. In its current version, the library of inference methods implemented in PLOM is constructed around the particle Marginal Metropolis Hastings algorithm (pMMH), which is one of the two versions of the particle Markov Chain Monte Carlo algorithm (pMCMC) \citep{Andrieu2010}. Along with this algorithm, PLOM provides with a series of tools to ensure and facilitate  the convergence and efficient  performance of the pMCMC algorithm. It further provides with automatic diagnostic tools based on the CODA package \citep{Plummer2006}, and encourages peer validation for  results published on PLOM.IO. We will introduce the different inference tools in the remainder of this section, and motivate and illustrate their combination in the following one.


\subsection{Conditional state exploration: $p(x_{0:n}|y_{1:n},\theta)$ and $p(y_{1:n}|\theta)$}

\paragraph{Sequential Monte Carlo}\mbox{}\\
Sequential Monte Carlo (SMC) methods, also known as particle filters in this setting, provide an efficient solution to explore the space of trajectories of the system conditioned on a given parameter $\theta$ and available observations $y_{1:n}$. They are targeted to problems where the target density is sequentially structured, and  can be decomposed as a product of terms. These terms are aggregated progressively in order to  achieve a smooth transfer from a simple initial density corresponding to a single term of the product, up to the full target density. For example, for state space models the algorithm starts by approximating the prior density of initial conditions $p(x_0|\theta)$ with a swarm of samples called particles. At each iteration of the algorithm, an additional observation is accounted for, progressively increasing the dimension of the explored state. Particles are weighted according to how well they fit the new datapoint, and a resampling step is made to ensure that the exploration focuses on informative regions of the target space. 


A classic version of the SMC algorithm, referred to as Systematic Importance Resampling algorithm, is presented in Algorithm \ref{alg:SMC} \citep{Doucet2009}. If $J$ is the number of particles,  this algorithm can provide  a sample $\tilde{x}_{0:n}$ from $\hat{p}^J_{pf}(x_{0:n}|y_{1:n })$, and an unbiased estimator $\hat{p}^J_{pf}(y_{1:n}|\theta)$ of $p(y_{1:n}|\theta)$. Under mild assumptions, the authors of \cite{Moral2004} and \cite{Andrieu2010} have proved the following properties:
\begin{IEEEeqnarray}{rCl}
	%\mathbb{E}[\hat{p}^J_{pf}(y_{1:n}|\theta)] &=& p(y_{1:n}|\theta)\nonumber\\
	\Vert \hat{p}^J_{pf}(x_{0:n}|y_{1:n }) - p(x_{0:n}|y_{1:n }) \Vert &\leq& \frac{C_n}{J}\\
	Var(\frac{\hat{p}^J_{pf}(y_{1:n}|\theta)}{p(y_{1:n}|\theta)}) &\leq&  \frac{D_n}{J}\nonumber
\end{IEEEeqnarray} 


Where $C_n$ and $D_n$ are constants depending on the model and on the number of observations $n$. The distance $\Vert p_2-p_1 \Vert$  is defined as the total variation distance between the two distributions. Consequently, the particle filter is a solution to achieve asymptotically exact estimation of
%exploration of the density $p(x_{0:n}|y_{1:n},\theta)$ with the precision of 
the  marginal likelihood with precisions increasing as $O(J^{1/2})$. 
\begin{algorithm}
\caption{Sequential Monte Carlo algorithm}
\label{alg:SMC}
\begin{algorithmic}
\STATE Set $L=1$, $W_{0}^{(j)}=\frac{1}{J}$, sample $(x_{0}^{(j)})_{j=1,...,J}$ from $p(x_0|\theta)$ 
\FOR {$k=0$ to $n-1$}
	\FOR {$j=1$ to $J$}
		\STATE Sample $(x_{k:k+1}^{(j)})$ from $p(x_{k:k+1}|x_k,\theta)$  
		\STATE Set $\alpha^{(j)}= h(y_{k+1},x^{(j)}_{k+1},\theta)$
	\ENDFOR
	\STATE Set $W_{k+1}^{(j)}=\frac{\alpha^{(j)}}{\sum_{l=1}^{J}\alpha^{l}}$, and $L=L\times \frac{1}{J} \sum_j \alpha^{(j)}$
	\STATE Resample $(x_{0:k+1}^{(j)})_{j=1,\dots,J}$ according to $(W_{k+1}^{(j)})$,
\ENDFOR		
\end{algorithmic}
\end{algorithm}




\paragraph{Extended Kalman Filter}\mbox{}\\
An approximate solution to the filtering problem for state space models is provided by the Extended Kalman Filter (EKF) algorithm \citep{Jazwinski1970,Sarkka2006}. We consider its continuous-discrete version tailored  to dynamic models formulated as stochastic differential equations, with $\mu$  corresponding to the drift component of the model (which Jacobian is noted $\nabla\mu$), and diffusion and dispersion matrices being respectively noted $Q$ and $L$. $R_k$ is the variance of the observation process at time $k$. The EKF, described in Algorithm \ref{alg:EKF},  is based on a gaussian approximation of the observation process $h$ (which Jacobian is noted $\nabla h$), resulting in a multivariate normal density for $p(x_t|y_{0:n})$ characterised by its mean $m_t$ and covariance $C_t$. It provides with a deterministic and biased estimate $p^{EKF}(y_{1:n}|\theta)$ of the marginal likelihood.


Note that in Algorithm \ref{alg:EKF},  only one observations is integrated at each time step. In the case of simultaneous observations, the same steps can be followed several time to update iteratively the mean and covariance of the state vector, observation per observation.


\begin{algorithm}
\caption{Continuous-discrete Extended Kalman Filter algorithm}
\label{alg:EKF}
\begin{algorithmic}
\STATE Set $L=1$ and initialise the mean state $m_t$ and covariance $C_t$
\FOR {$k=1$ to $n$}
	\STATE Integrate between $t_{k-1}$ and $t_{k}$:\\
		$\;\;\;\;\;\;\frac{dm_t}{dt}=\mu(m_t,\theta)$\\
		$\;\;\;\;\;\;\frac{dC_t}{dt}=\nabla\mu(m_t,\theta)C_t + C_t \nabla\mu(m_t,\theta)^T+LQL'$
	\STATE Compute the prediction error $e = y_{k}- h(m_{t_{k}},\theta)$, and the following quantities:\\
		$\;\;\;\;\;\;S=\nabla h(m_{t_{k}},\theta) C_{t_k} \nabla h(m_{t_{k}},\theta)'+R_{t_k}$	\\
		$\;\;\;\;\;\;K=C_{t_k}\nabla h'(m_t,\theta)S^{-1}$\\
	\STATE Update the mean state and Covariance:\\
		$\;\;\;\;\;\;m_t = m_t + K e$\\
		$\;\;\;\;\;\;C_t = C_t - KSK'$	
	\STATE Update the likelihood $L(\theta) = L(\theta)\times\mathcal{N}(e;0,S)$
\ENDFOR		
\end{algorithmic}
\end{algorithm}

\subsection{Full inference of paths and parameters}

\subsubsection{Introduction to the Monte Carlo Markov Chain machinery}

Monte Carlo Markov Chain (MCMC) methods are used to estimate properties of probability densities in cases where analytic formulas cannot be directly derived, and samples cannot be directly generated. If we note $x$ ($x\in\mathbb{R}^d$) the  random variable of a target density  $\pi(.)$, MCMC algorithms only require the ability to compute $\pi(x)$ for any $x$, up to a multiplicative factor. Their founding mechanism is the construction of a Markov chain that randomly explores $\mathbb{R}^d$ taking values $(x^{(1)},x^{(2)},..,x^{(N)})$ which will asymptotically mimic samples drawn from the target distribution. The chain is defined through a transition kernel $K$ that determines the transition probability $p(.|x^{(i-1)})$. The chain converges to an invariant distribution if K is irreducible (from any state there is a positive probability to visit any other state) and aperiodic. The detailed balance condition is a sufficient but not necessary condition to ensure that the invariant distribution of the chain is the target density $\pi$:
\begin{align}
	\pi(x^i)K(x^{(i-1)}|x^{(i)}) = \pi(x^{(i-1)})K(x^{(i)}|x^{(i-1)})
\end{align}


A critical dimension of MCMC algorithms is their efficiency in $mixing$, i.e. in generating samples that are  as independent as possible. Unless $K(.|x^{(i)})$ is equal to  $\pi(.)$, $N$ samples of the MCMC trajectory will not provide the same amount of information as $N$ independent and identically distributed (i.i.d.) samples from the target density $\pi$. This can be quantified by the \emph{Effective Sample Size} (ESS), for example, that estimates how many truly i.i.d. samples the MCMC  output is equivalent to \citep{Geyer1992, Brooks1998}: 
\begin{align}
	ESS(\{x^{(1)},x^{(2)},..,x^{(N)}\}) = \frac{N}{1+2\sum_{k=1}^{k^{max}}Correl(\{x^{(1)},..,x^{(N-k)}\},\{x^{(k)},..,x^{(N)}\})}
\end{align}

This indicator will be used in this thesis to assess the efficiency of MCMC algorithms utilised to explore the complex and high-dimensional target density $p(x_{0:n},\theta|y_{0:n})$. Before diving into the presentation of basic and more advanced MCMC algorithms, we introduce the most classic way to define transition kernels that respect the detailed balance condition: the Metropolis-Hastings step \citep{Metropolis1953,Hastings1970}. At each iteration of the chain, a proposed value $x^*$ is sampled from an importance distribution $q(.|x^{(i)})$, and accepted with probability:
\begin{align}
	1\wedge \frac{\pi(x^*)q(x^{(i)}|x^*)}{\pi(x^{(i)})q(x^*|x^{(i)})}
\end{align}
Otherwise, $x^{i+1}$ is set equal to $x^{i}$. The proportion of proposed samples that have been accepted determine the acceptance rate.  The Metropolis Hastings step allows the use of any importance distribution $q$ respecting the irreducibility and aperiodicity conditions, although other choices are also possible. It is generally observed that increasing the dimension of $x$ decrease the acceptance probability. The Gibbs algorithm offers a first solution to this problem: at each iteration of the chain each component (or group of components) of $x$ is updated independently, conditionally on the values of the others. This strategy can be useful when the marginal conditional density of the components being updated is tractable or easy to be sampled from. It can nevertheless induce poor mixing if the components being updated are strongly correlated to the ones they are being conditioned on.



\begin{algorithm}[h]
\caption{random walk Metropolis algorithm}
\label{alg:Intro_MH}
\begin{algorithmic}
\STATE Initialise $x^{(0)}$
\FOR {$i=0$ to $N$}
	\STATE Sample $x^*\sim \mathcal{N}(x^{(i)}, \Sigma^q)$
	\STATE Accept $x^*$ with probability $1\wedge\frac{\pi(x^*)}{\pi(x^{(i)})}$
\ENDFOR
\end{algorithmic}
\end{algorithm}

The random walk Metropolis is  based on Metropolis-Hastings steps using a multivariate normal importance sampling distribution: $q(.|x^{(i)})=\mathcal{N}(x^{(i)},\Sigma^q)$ (see Algoritm \ref{alg:Intro_MH}). The efficiency of this algorithm on a given problem depends on the calibration of the covariance matrix $\Sigma^q$.
Theoretical results have been demonstrated in the situation where the target  distribution $\pi$  is  a multivariate normal density:

\begin{prop}
	When $\pi$ is  a multivariate normal density, the acceptance rate that maximises the mixing efficiency of the random walk Metropolis algorithm is $23.4\%$ \citep{Roberts1997}
\end{prop}

\begin{prop}
	When $\pi$ is  a multivariate normal density, optimal results are achieved by using $\Sigma^q = \frac{2.38^2}{d}\times Cov(\pi)$ \citep{Roberts1997}.
\end{prop}

When the target distribution is not a multivariate normal density, these results are extrapolated and followed as rules of conduct. They were used to derive adaptive versions of the random walk Metropolis algorithm, based on a decomposition of $\Sigma^q$ into $\lambda\Sigma$. A first adaptive algorithm exploits the monotonicity of the acceptance rate as a function of $\lambda$. The Metropolis-Hastings ratio of a random walk Metrpopolis algorithm is $\frac{\pi(x^*)}{\pi(x)}$. Hence, if the mass of the target density is concentrated in a certain region and $x$ is in this region (which is the case with high probability if the chain has converged), increasing the value of $\lambda$ increases the risk for $x^*$ to escape that region, leading to low values of $\pi(x^*)$ and rejection of $x^*$. On the contrary, excessively small values of $\lambda$ will induce values of $\frac{\pi(x^*)}{\pi(x)}$ close to one and high acceptance rates. Therefore, the targeted acceptance rate can be approached by iteratively adapting $\lambda$ with a cooling rate $a\in[0;1[$:
\begin{align}
	\lambda_{i+1} = \lambda_{i}\times a^i(AccRate_i-0.234)
\end{align}

A second adaptive algorithm relies on the fact that, as the chain progresses, the generated samples are meant to mimick i.i.d. samples generated from the target distribution $\pi$. Consequently, the empirical covariance matrix obtained from these samples can be used as a proxy for the optimal covariance matrix $\frac{2.38^2}{d}\times Cov(\pi)$. The resulting adaptive algorithm proposed in \cite{Roberts2009} is based on the following importance sampling distribution:
\begin{align}
q(.|x^{(i)})=\alpha \mathcal{N}\left(x^{(i)},\lambda\frac{2.38^2}{d}\Sigma^{(0)}\right) +(1-\alpha)\mathcal{N}\left(x^{(i)},\lambda\frac{2.38^2}{d}\Sigma^{(i)}\right)
\end{align}

With $\Sigma_i$ being the empirical  covariance matrix obtained from the $i$ samples generated by the chain. The use of a mixture of normal distributions ($\alpha$ is generally set to 0.05) is meant to avoid convergence to local modes.




\subsubsection{Particle Marginal Metropolis Hastings algorithm}
Filtering techniques are a natural choice to explore $p(x_{0:n}|y_{1:n},\theta)$. In order to  account for  uncertainties regarding the parameter vector $\theta$, we are aiming for the exploration of the joint posterior density $p(x_{0:n},\theta|y_{1:n})$. As previously mentioned,  classic MCMC methods fail to be efficient and robust solutions because of the high dimension of the target density. The particle MCMC algorithm  offers a solution relying on the efficiency of particle filters \citep{Andrieu2010}. Algorithm \ref{alg:PMCMC} illustrates the principles of its particle marginal Metropolis Hastings version: the high-dimensional density exploration problem is reduced to the design of an MCMC algorithm over $\theta$, based on the likelihood $\hat{p}_{pf}(y_{1:n}|\theta)$ estimated by a particle filter conditioned on $\theta$. The authors of \cite{Andrieu2010} have shown that the algorithm was asymptotically exact for a given discretisation of time, as under classic assumptions when the number of iterations $N^{\theta}$ tends to infinity:
\begin{align}
	\Vert \hat{p}^J_{pf}(x^{(i)}_{0:n},\theta^{(i)}|y_{1:n}) -  p(x_{0:n},\theta|y_{1:n}) \Vert \rightarrow 0 \;\;\;\;\; as \; i\rightarrow \; \infty
\end{align}

Every iteration of the MCMC algorithm implies running a particle filter to explore the range of likely paths of the system under the current value of $\theta$. Consequently, the pMCMC is a computationally demanding algorithm; its complexity if of the order of $O(n J  N^{\theta})$. The mixing efficiency of the MCMC scheme critically determines the applicability of the algorithm. In the absence of suitable techniques to efficiently estimate the marginal score $\nabla_{\theta} \log p(\theta|y_{1:n})$, random walk Metropolis algorithms are generally used. Even in its adaptive form, the parameterisation of its initial covariance matrix $\Sigma^q_0$ is a central issue: we will explore in Chapter 2 a mean to automatise this process, rendering the pMCMC algorithm plug-and-play. 


\begin{algorithm}[h]
\caption{Particle MCMC algorithm (particle marginal Metropolis Hastings version)}
\label{alg:PMCMC}
\begin{algorithmic}
\STATE Initialise $\theta^{(0)}$.
\STATE Use Particle Smoother to compute  $\hat{p}(y_{1:n}|\theta^{(0)})$ and sample $x^{(0)}_{0:n}$ from $p(x^{dis}_{0:n}|y_{1:n},\tilde{\theta})$
\FOR {$i=1$ to $N^{\theta}$}
	\STATE Sample $\theta^{*}$ from $q(.|\theta^{(i)})$
	\STATE Use PS to compute $L(\theta^*)$ and sample $x_{0:n}^{*}$ from $\hat{p}(x^{dis}_{0:n}|y_{1:n},\theta^*) $
	\STATE Accept $\theta^{*}$ (and  $x_{0:n}^{*}$) with probability $1\wedge\frac{L(\theta^{*})q(\theta^{(i)}|\theta^{*})}{L(\theta^{(i)})q(\theta^{*}|\theta^{(i)})}$
	\STATE Record $\theta^{(i+1)}$ and $x^{(i+1)}_{1:n}$
\ENDFOR
\end{algorithmic}
\end{algorithm}


An alternative solution is the $SMC^2$ algorithm presented in \cite{Chopin2012}. It explores both the probability density of $x_{0:n}$ and $\theta$ with an SMC algorithm, starting from the initial target $p(x_0,\theta)$ and progressively incorporating  the available observations. The global complexity of this algorithm is similar to the PMCMC, but its ability to automatically adapt the number particles being utilised and to progressively learn from previous samples what could be seen as the equivalent of the covariance matrix $\Sigma^q$ are promising features. At last, an asymptotically exact and plug-and-play  solution to the frequentist problem of  maximising the marginal likelihood $p(y|\theta)$ has been proposed in \cite{Ionides2006} and later in  \cite{Ionides2011}. This approach has been used for several applications in epidemiology, and it can be used to efficiently initialise the Markov chain of the PMCMC by incorporating the prior density into the maximised function of $\theta$.


\subsubsection{Efficiently initialisation and calibration of the PMMH algorithm}
\section{Iterated inference pipeline: illustrations}
\section{Perspectives: call for contributions}










\bibliographystyle{apalike} % numeric style

\bibliography{Biblio}


 \end{document}